### ConcurrentHashMap原理

#### 死链问题

首先我们来说说jdk7 HashMap会造成的死链问题:

由于jdk7扩容的时候使用头插法:

两个线程参与扩容:A->B->C->D->E

线程2执行A->B的时候被线程1抢了执行权，而且线程1完成了迁移：

迁移完成后E->D->c->B->A，但是线程2还在A->B状态，由于迁移的时候用了2个变量记录了A.next和B.next，此时A.next为旧值，指向B。B.next为新值，指向A。结果就是A->B->A->B这样无限死循环



---



#### 构造方法

```java
public ConcurrentHashMap(int initialCapacity,
                         float loadFactor, int concurrencyLevel) {
    if (!(loadFactor > 0.0f) || initialCapacity < 0 || concurrencyLevel <= 0)
        throw new IllegalArgumentException();
    if (initialCapacity < concurrencyLevel)   // Use at least as many bins
        initialCapacity = concurrencyLevel;   // as estimated threads
    long size = (long)(1.0 + (long)initialCapacity / loadFactor);
    int cap = (size >= (long)MAXIMUM_CAPACITY) ?
        MAXIMUM_CAPACITY : tableSizeFor((int)size);
    this.sizeCtl = cap;
}
```

参数校验

```java
if (!(loadFactor > 0.0f) || initialCapacity < 0 || concurrencyLevel <= 0)
    throw new IllegalArgumentException()
```

保证有足够的桶数量，桶数量不低于并发数

```java
if (initialCapacity < concurrencyLevel)   // Use at least as many bins
    initialCapacity = concurrencyLevel; 
```

使用公式计算初始表大小，initialCapacity 为预期存放元素的数量，负载因子用来扩容的，是用户存进去的，为了达到负载因子用于扩容这个目的，我们不能够让 initialCapacity 就扩容，必须要到达负载因子计算的阈值才能扩容，+1的目的是向上取整，因为整除可能向下取整的，我们要往大的取

> size = 1 + initialCapacity / loadFactor

这里重点是分析tableSizeFor这个方法，这个方法是用来返回一个向上取整的 2的n次方数字，作为表空间。为什么一定要是2的n次方，这个跟后面计算hash是有关系的，这里后面再说

```java
private static final int tableSizeFor(int c) {
        // numberOfLeadingZeros这个方法是告诉你有多少个零的，
    // 比如00000000 00000000 00000000 00001100前面就要28个0
    // 然后再用-1去移位，获取到2的幂次方。比如这里得到的结果就是15
    // 为什么要用-1移位，因为-1的补码是11111111 .....  11111111（32个1）,无符号右移刚好就能得到我们想要的二进制计算大小
    // n返回边界值长度就是15
    int n = -1 >>> Integer.numberOfLeadingZeros(c - 1);
    return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
}
```

这里我们看看numberOfLeadingZeros，这个方法，这个方法很巧妙，用来计算c前面有多少个0的，他是用了二分法的思想去找前面有多少个零的。

```java
public static int numberOfLeadingZeros(int i) {
    // HD, Count leading 0's
    if (i <= 0)
        return i == 0 ? 32 : 0;
    int n = 31;
    if (i >= 1 << 16) { n -= 16; i >>>= 16; }
    if (i >= 1 <<  8) { n -=  8; i >>>=  8; }
    if (i >= 1 <<  4) { n -=  4; i >>>=  4; }
    if (i >= 1 <<  2) { n -=  2; i >>>=  2; }
    return n - (i >>> 1);
}
```

我们以

0100 0000 0000 0000  0000 0000 0000 0000

这个数字前面有1个零，所以最终结果应有一个零。

int是32位的，使用二分法。**我们先去找他高16位有没有1**，

> if (i >= 1 << 16)

 1 << 16 ：左移16位之后，数值为：

0000 0000 0000 0001  0000 0000 0000 0000

然后比较一下与i的大小，如果i大于1 << 16，证明数值坐落在高16位，那二分法的下一步，就是要把高16位分成2份，看看是坐落在高16位中的前8位，还是后八位。这里做了个很巧妙的事情，就是缩小数值，方便计算：

> n -= 16; i >>>= 16

我只需要知道有多少个零，既然低16位都是有数值的，零出现在高16位，那我干脆直接 把低16位丢弃（不关心数值），同时记录零个数的n也以前减去16.缩小范围（坐落在高16位，最多就是15个0，所以n同步变化）。经过这一部，数值变为

0000 0000 0000 0000 0100 0000 0000 0000

前面16个零已经可以不用管了，这是移位生成的数字，我只需要继续对这个数字进行二分查找，判断零是高8位还是低8位，继续二分查找，后面的if (i >= 1 <<  4)跟if (i >= 1 <<  2)都是依次操作

**............................**

最后，经过if (i >= 1 <<  2)，数字变成了

0000 0000 0000 0000 0000 0000 0000 0001

n变成了1

最后一步if (i >= 1 <<  2)二分法把最终结果分成了2位数字，所以我们要看看是出现在低1位还是高1位。

最后一步i >>> 1就知道了是在低1位还是高1位。

最后n - (i >>> 1)就能得到多少个零了

---

#### get方法

```java
public V get(Object key) {
    Node<K,V>[] tab; Node<K,V> e, p; int n, eh; K ek;
    // 减少hash冲突的方法
    int h = spread(key.hashCode());
    // 已经初始化，而且用tabAt找到桶位置
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (e = tabAt(tab, (n - 1) & h)) != null) {
        // 在桶的头部就可以直接返回了
        if ((eh = e.hash) == h) {
            if ((ek = e.key) == key || (ek != null && key.equals(ek)))
                return e.val;
        }
        // hash值为负表示特殊节点，如扩容中的ForwardingNode，交给find方法去找
        else if (eh < 0)
            return (p = e.find(h, key)) != null ? p.val : null;
        // 不在桶头部就要遍历这个链表
        while ((e = e.next) != null) {
            if (e.hash == h &&
                ((ek = e.key) == key || (ek != null && key.equals(ek))))
                return e.val;
        }
    }
    return null;
}
```

spread方法：

这个方法其实是用来计算key的hash值的，包括后面put的时候也是用这个方法，这是为了减少hash冲突，有些hash值它是集中在前16位，后16位为0（hash值为int长度为32），全是这种key的电话hash值冲突会过多，全部放在桶的一个位置，所以为了保证它前16位与后16位都能用上，这里用了前16位与后16位的与运算，假如右移8为异或运算实际上就是8位与8位的异或，效果也没有移位16好

```java
static final int spread(int h) {
    return (h ^ (h >>> 16)) & HASH_BITS;
}
```

tabAt用到是unsafe方法，我们不管

e.find(h, key)方法实际上与while ((e = e.next) != null) 逻辑差不多，一个用while，-一个用do-while，find方法如果用while的话还有对e进行判空，这里会加点消耗，所以单独抽出来用do-while

```java
Node<K,V> find(int h, Object k) {
    Node<K,V> e = this;
    if (k != null) {
        do {
            K ek;
            if (e.hash == h &&
                ((ek = e.key) == k || (ek != null && k.equals(ek))))
                return e;
        } while ((e = e.next) != null);
    }
    return null;
}
```

整个get方法都是没有加锁的，**所以说遍历的时候时弱一致性，因为遍历的时候可以有其他线程put修改**，通过Node节点的2个volatile字段保证可见性，所以无需加锁

```java
volatile V val;
volatile Node<K,V> next;
```

---

#### put方法

这里值得注意的是sychronized加锁加的是操作桶的位置，addSize负责统计数量并扩容，初始化加的锁时桶。增加元素用的时synchronized

```Java
/** Implementation for put and putIfAbsent */
final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) throw new NullPointerException();
    int hash = spread(key.hashCode());
    int binCount = 0;
    for (Node<K,V>[] tab = table;;) {
        Node<K,V> f; int n, i, fh; K fk; V fv;
        // 初始桶
        if (tab == null || (n = tab.length) == 0)
            tab = initTable();
        // 如果没桶情况下，cas操作向桶数组的第i个位置放一个新的节点，成功break
        else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
            // 桶是加cas锁的
            if (casTabAt(tab, i, null, new Node<K,V>(hash, key, value)))
                break;                   // no lock when adding to empty bin
        }
        // 有桶，==MOVED意味着在初始化，或者是在扩容，这里弄了个帮助扩容的操作
        else if ((fh = f.hash) == MOVED)
            tab = helpTransfer(tab, f);
        // onlyIfAbsent不会用新增覆盖旧值，它这里就是判断头部位置有而且onlyIfAbsent为true那那就不覆盖了
        else if (onlyIfAbsent // check first node without acquiring lock
                 && fh == hash
                 && ((fk = f.key) == key || (fk != null && key.equals(fk)))
                 && (fv = f.val) != null)
            return fv;
        else {
            V oldVal = null;
            // 加同步锁
            synchronized (f) {
                // 找桶位置
                if (tabAt(tab, i) == f) {
                    if (fh >= 0) {
                        binCount = 1;
                        // 遍历链表
                        for (Node<K,V> e = f;; ++binCount) {
                            K ek;
                            // 如果存在相同的key，根据onlyIfAbsent判断释放覆盖
                            if (e.hash == hash &&
                                ((ek = e.key) == key ||
                                 (ek != null && key.equals(ek)))) {
                                oldVal = e.val;
                                if (!onlyIfAbsent)
                                    e.val = value;
                                break;
                            }
                            // 没有旧直接往链表新增节点
                            Node<K,V> pred = e;
                            if ((e = e.next) == null) {
                                pred.next = new Node<K,V>(hash, key, value);
                                break;
                            }
                        }
                    }
                    // 红黑树情况下，用红黑树方法put节点
                    else if (f instanceof TreeBin) {
                        Node<K,V> p;
                        binCount = 2;
                        if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                       value)) != null) {
                            oldVal = p.val;
                            if (!onlyIfAbsent)
                                p.val = value;
                        }
                    }
                    else if (f instanceof ReservationNode)
                        throw new IllegalStateException("Recursive update");
                }
            }
            // 链表转红黑树
            if (binCount != 0) {
                if (binCount >= TREEIFY_THRESHOLD)
                    treeifyBin(tab, i);
                if (oldVal != null)
                    return oldVal;
                break;
            }
        }
    }
    // node数量统计，并扩容，这里还没锁
    addCount(1L, binCount);
    return null;
}
```

---

#### initTable

U.compareAndSetInt(this, SIZECTL, sc, -1) cas操作设置SIZECTL为-1，其他线程进来发现if ((sc = sizeCtl) < 0)，就会明白正在初始化，然后用 Thread.yield()挂起

```java
private final Node<K,V>[] initTable() {
    Node<K,V>[] tab; int sc;
    while ((tab = table) == null || tab.length == 0) {
        // 小于0证明正在初始化
        if ((sc = sizeCtl) < 0)
            // 通知cpu挂起线程
            Thread.yield(); // lost initialization race; just spin
        // cas设置SIZECTL为-1
        else if (U.compareAndSetInt(this, SIZECTL, sc, -1)) {
            try {
                if ((tab = table) == null || tab.length == 0) {
                    // sc就是前面的sizeCtl，这个sizeCtl是在构造函数的时候计算出来的长度
                    int n = (sc > 0) ? sc : DEFAULT_CAPACITY;
                    @SuppressWarnings("unchecked")
                    Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
                    table = tab = nt;
                    // n>>>2 就是 n/4，这里是计算扩容阈值
                    sc = n - (n >>> 2);
                }
            } finally {
                // sizeCtl有两个作用，一个是初始化时数组长度，第二个是扩容阈值
                sizeCtl = sc;
            }
            break;
        }
    }
    return tab;
}
```

这里面有一个问题：sizeCtl = sc为下次扩容阈值，但是我们看到sc是通过n - (n >>> 2)计算的。也就是n-n/4。也就是负载因子是固定0.75f，但是我们知道我们构造函数的时候不是也传了一个负载因子吗？那这个负载因子是没有用的？

其实构造函数传入的负载因子在ConcurrentHashMap确实没多大用，它扩容的时候负载因子写死是0.75f，这个是人家计算出来的最优结果，至于我们在构造函数传入的负载因子，作用临时参与初始容量计算，保证有足够的初始容量，不会一进来就扩容

---

#### addCount

这个方法分成两步：

1.统计数量

2.扩容



首先讲统计数量，CounterCell这东西其实跟LongAddr原理差不多，不懂的回去看LongAddr原理

```java
private final void addCount(long x, int check) {
    // 1. 统计数量
    CounterCell[] cs; long b, s;
    // 直接尝试修改数量baseCount，(cs = counterCells) != null不成立的话，意味着CounterCell未初始化，这时候直接尝试修改
    if ((cs = counterCells) != null ||
        !U.compareAndSetLong(this, BASECOUNT, b = baseCount, s = b + x)) {
        CounterCell c; long v; int m;
        boolean uncontended = true;
        if (cs == null || (m = cs.length - 1) < 0 ||
            (c = cs[ThreadLocalRandom.getProbe() & m]) == null ||
            !(uncontended =
              U.compareAndSetLong(c, CELLVALUE, v = c.value, v + x))) {
            fullAddCount(x, uncontended);
            return;
        }
        if (check <= 1)
            return;
        s = sumCount();
    }
    // 2.扩容
    if (check >= 0) {
        Node<K,V>[] tab, nt; int n, sc;
        while (s >= (long)(sc = sizeCtl) && (tab = table) != null &&
               (n = tab.length) < MAXIMUM_CAPACITY) {
            int rs = resizeStamp(n) << RESIZE_STAMP_SHIFT;
            if (sc < 0) {
                if (sc == rs + MAX_RESIZERS || sc == rs + 1 ||
                    (nt = nextTable) == null || transferIndex <= 0)
                    break;
                if (U.compareAndSetInt(this, SIZECTL, sc, sc + 1))
                    transfer(tab, nt);
            }
            else if (U.compareAndSetInt(this, SIZECTL, sc, rs + 2))
                transfer(tab, null);
            s = sumCount();
        }
    }
}
```



首先看这个判断，(cs = counterCells) != null不成立的话，意味着CounterCell未初始化，这时候直接尝试修改。这时cas修改baseCount，这个baseCount是基础数量的意思，为了提高并发量，整个CurrentHashMap的数量分为两部分:基础数量baseCount + Cell数组中的cell value总和。统计数量时，它会先尝试修改baseCount数量，修改成功也就不会有Cell操作，修改失败证明有并发，才会有Cell操作。

```java
if ((cs = counterCells) != null ||
    !U.compareAndSetLong(this, BASECOUNT, b = baseCount, s = b + x))
```

假如都失败了，就要走Cell操作了

```java
boolean uncontended = true;
if (cs == null || (m = cs.length - 1) < 0 ||
    (c = cs[ThreadLocalRandom.getProbe() & m]) == null ||
    !(uncontended =
      U.compareAndSetLong(c, CELLVALUE, v = c.value, v + x))) {
    fullAddCount(x, uncontended);
    return;
}
if (check <= 1)
    return;
s = sumCount();
```

首先看这个判断

```java
if (cs == null || (m = cs.length - 1) < 0 ||
    (c = cs[ThreadLocalRandom.getProbe() & m]) == null ||
    !(uncontended =
      U.compareAndSetLong(c, CELLVALUE, v = c.value, v + x)))
```

cs == null || (m = cs.length - 1) < 0未初始化；c = cs[ThreadLocalRandom.getProbe() & m]) == null与这个线程相关的Cell为null；假设前面两个都不成立，证明有Cell数组了，而而且有想要的Cell了。这时尝试直接修改Cell的值：

```
(uncontended =
  U.compareAndSetLong(c, CELLVALUE, v = c.value, v + x))
```

注意，这里加到锁是CELLVALUE，加锁还是失败了，证明**有Cell在操作**，那我这时就要走fullAddCount(x, uncontended)去进行更加完全的操作了。这个方法一旦加锁，就是加的整个Cell数组了，**fullAddCount中的CELLSBUSY作为锁。**

我们可以注意到这里有个boolean uncontended = true;**这个是用来提示后面fullAddCount方法走什么分支的**，假如if中前两个判断，cs == null || (m = cs.length - 1) < 0 || (c = cs[ThreadLocalRandom.getProbe() & m]) == null这两个条件已经成了，就不会走后面的 !(uncontended =
      U.compareAndSetLong(c, CELLVALUE, v = c.value, v + x))，那意味着fullAddCount传进去的是 true。提示fullAddCount做初始化相关工作（初始化Cell数组或者Cell），接下来我们看看fullAddCount这个方法



这个方法逻辑实际上与LongAddr大同小异

```java
private final void fullAddCount(long x, boolean wasUncontended) {
    int h;
    if ((h = ThreadLocalRandom.getProbe()) == 0) {
        ThreadLocalRandom.localInit();      // force initialization
        h = ThreadLocalRandom.getProbe();
        wasUncontended = true;
    }
    boolean collide = false;                // True if last slot nonempty
    for (;;) {
        CounterCell[] cs; CounterCell c; int n; long v;
        if ((cs = counterCells) != null && (n = cs.length) > 0) {
            if ((c = cs[(n - 1) & h]) == null) {
                if (cellsBusy == 0) {            // Try to attach new Cell
                    CounterCell r = new CounterCell(x); // Optimistic create
                    if (cellsBusy == 0 &&
                        U.compareAndSetInt(this, CELLSBUSY, 0, 1)) {
                        boolean created = false;
                        try {               // Recheck under lock
                            CounterCell[] rs; int m, j;
                            if ((rs = counterCells) != null &&
                                (m = rs.length) > 0 &&
                                rs[j = (m - 1) & h] == null) {
                                rs[j] = r;
                                created = true;
                            }
                        } finally {
                            cellsBusy = 0;
                        }
                        if (created)
                            break;
                        continue;           // Slot is now non-empty
                    }
                }
                collide = false;
            }
            else if (!wasUncontended)       // CAS already known to fail
                wasUncontended = true;      // Continue after rehash
            else if (U.compareAndSetLong(c, CELLVALUE, v = c.value, v + x))
                break;
            else if (counterCells != cs || n >= NCPU)
                collide = false;            // At max size or stale
            else if (!collide)
                collide = true;
            else if (cellsBusy == 0 &&
                     U.compareAndSetInt(this, CELLSBUSY, 0, 1)) {
                try {
                    if (counterCells == cs) // Expand table unless stale
                        // 数量*2
                        counterCells = Arrays.copyOf(cs, n << 1);
                } finally {
                    cellsBusy = 0;
                }
                collide = false;
                continue;                   // Retry with expanded table
            }
            h = ThreadLocalRandom.advanceProbe(h);
        }
        // 初始化数组
        else if (cellsBusy == 0 && counterCells == cs &&
                 U.compareAndSetInt(this, CELLSBUSY, 0, 1)) {
            boolean init = false;
            try {                           // Initialize table
                if (counterCells == cs) {
                    CounterCell[] rs = new CounterCell[2];
                    rs[h & 1] = new CounterCell(x);
                    counterCells = rs;
                    init = true;
                }
            } finally {
                cellsBusy = 0;
            }
            if (init)
                break;
        }
        // 尝试直接给基础数量修改
        else if (U.compareAndSetLong(this, BASECOUNT, v = baseCount, v + x))
            break;                          // Fall back on using base
    }
}
```

这里如果有看不懂的可以看看LongAddr，值得注意的点是：初始化的时候，加锁加的是CELLSBUSY，这是范围更大的锁。还有最后的竞争失败尝试直接cas基础数量，这个也是提高并发操作



在addCount这个方法的最后

```java
// check入参如果小于1就不考虑扩容了
if (check <= 1)
    return;
// 汇总数量
s = sumCount();
```

汇总数量这个方法可以看一看，实际上就是把所有cell跟baseCount数量相加

```java
final long sumCount() {
    CounterCell[] cs = counterCells;
    long sum = baseCount;
    if (cs != null) {
        for (CounterCell c : cs)
            if (c != null)
                sum += c.value;
    }
    return sum;
}
```

汇总的方法其实也是可以看到，**它跟put压根没有加同一个锁，所以统计数量也是保持弱一致性**





接下来我们看第二部分：**扩容**

扩容流程：

1.领取任务，任务区间位[bound,i]，领取到的任务负载处理这个区间的迁移。

2.对迁移中的桶进行加synchronize锁，防止出现死链问题







```java
// 2.扩容
if (check >= 0) {
    Node<K,V>[] tab, nt; int n, sc;
    // 1.以及超过阈值    2.初始化过  3.小于最大容量
    while (s >= (long)(sc = sizeCtl) && (tab = table) != null &&
           (n = tab.length) < MAXIMUM_CAPACITY) {
        // 基于桶长度生成一个唯一扩容标识
        int rs = resizeStamp(n) << RESIZE_STAMP_SHIFT;
        if (sc < 0) {
            if (sc == rs + MAX_RESIZERS    // 扩容线程数已达最大值
                || sc == rs + 1   // 扩容已完成？
                ||(nt = nextTable) == null  // 扩容目标表未初始化
                || transferIndex <= 0) // 需要迁移的区间已分配完
                break; // 不参与扩容
            if (U.compareAndSetInt(this, SIZECTL, sc, sc + 1))
                // 协助数据扩容
                transfer(tab, nt);   
        }
        else if (U.compareAndSetInt(this, SIZECTL, sc, rs + 2))
            // 发起新的扩容
            transfer(tab, null);
        s = sumCount();
    }
}
```



这里主要看transfer这个方法

```java
private final void transfer(Node<K,V>[] tab, Node<K,V>[] nextTab) {
    int n = tab.length, stride;
    // 让线程处理每个区间大小
    if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) < MIN_TRANSFER_STRIDE)
        stride = MIN_TRANSFER_STRIDE; // subdivide range
    // 初始化新表（2倍扩容）
    if (nextTab == null) {            // initiating
        try {
            @SuppressWarnings("unchecked")
            Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n << 1];
            nextTab = nt;
        } catch (Throwable ex) {      // try to cope with OOME
            sizeCtl = Integer.MAX_VALUE;
            return;
        }
        nextTable = nextTab;
        // 从右向左迁移
        transferIndex = n;
    }
    int nextn = nextTab.length;
    ForwardingNode<K,V> fwd = new ForwardingNode<K,V>(nextTab);
    // 控制任务领取
    boolean advance = true;
    // 最终完成标志
    boolean finishing = false; // to ensure sweep before committing nextTab
    for (int i = 0, bound = 0;;) {
        Node<K,V> f; int fh;
        // 任务领取逻辑
        while (advance) {
            int nextIndex, nextBound;
            if (--i >= bound || finishing)
                advance = false;
            else if ((nextIndex = transferIndex) <= 0) {
                i = -1;
                advance = false;
            }
            // 任务领取要加锁的，这里是修改TRANSFERINDEX的值，用于下个线程获取不同的区间计算
            else if (U.compareAndSetInt
                     (this, TRANSFERINDEX, nextIndex,
                      nextBound = (nextIndex > stride ?
                                   nextIndex - stride : 0))) {
                bound = nextBound;
                i = nextIndex - 1;
                advance = false;
            }
        }
        // 迁移完成检查
        if (i < 0 || i >= n || i + n >= nextn) {
            int sc;
            if (finishing) {
                nextTable = null;
                table = nextTab;
                sizeCtl = (n << 1) - (n >>> 1);
                return;
            }
            if (U.compareAndSetInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {
                if ((sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT)
                    return;
                finishing = advance = true;
                i = n; // recheck before commit
            }
        }
        // 空桶处理，插入一个fordwardNode节点
        else if ((f = tabAt(tab, i)) == null)
            advance = casTabAt(tab, i, null, fwd);
        // 已处理桶
        else if ((fh = f.hash) == MOVED)
            advance = true; // already processed
        // 实际迁移逻辑
        else {
            synchronized (f) {
                if (tabAt(tab, i) == f) {
                    Node<K,V> ln, hn;
                    if (fh >= 0) {
                        int runBit = fh & n;
                        Node<K,V> lastRun = f;
                        for (Node<K,V> p = f.next; p != null; p = p.next) {
                            int b = p.hash & n;
                            if (b != runBit) {
                                runBit = b;
                                lastRun = p;
                            }
                        }
                        if (runBit == 0) {
                            ln = lastRun;
                            hn = null;
                        }
                        else {
                            hn = lastRun;
                            ln = null;
                        }
                        for (Node<K,V> p = f; p != lastRun; p = p.next) {
                            int ph = p.hash; K pk = p.key; V pv = p.val;
                            if ((ph & n) == 0)
                                ln = new Node<K,V>(ph, pk, pv, ln);
                            else
                                hn = new Node<K,V>(ph, pk, pv, hn);
                        }
                        setTabAt(nextTab, i, ln);
                        setTabAt(nextTab, i + n, hn);
                        setTabAt(tab, i, fwd);
                        advance = true;
                    }
                    else if (f instanceof TreeBin) {
                        TreeBin<K,V> t = (TreeBin<K,V>)f;
                        TreeNode<K,V> lo = null, loTail = null;
                        TreeNode<K,V> hi = null, hiTail = null;
                        int lc = 0, hc = 0;
                        for (Node<K,V> e = t.first; e != null; e = e.next) {
                            int h = e.hash;
                            TreeNode<K,V> p = new TreeNode<K,V>
                                (h, e.key, e.val, null, null);
                            if ((h & n) == 0) {
                                if ((p.prev = loTail) == null)
                                    lo = p;
                                else
                                    loTail.next = p;
                                loTail = p;
                                ++lc;
                            }
                            else {
                                if ((p.prev = hiTail) == null)
                                    hi = p;
                                else
                                    hiTail.next = p;
                                hiTail = p;
                                ++hc;
                            }
                        }
                        ln = (lc <= UNTREEIFY_THRESHOLD) ? untreeify(lo) :
                            (hc != 0) ? new TreeBin<K,V>(lo) : t;
                        hn = (hc <= UNTREEIFY_THRESHOLD) ? untreeify(hi) :
                            (lc != 0) ? new TreeBin<K,V>(hi) : t;
                        setTabAt(nextTab, i, ln);
                        setTabAt(nextTab, i + n, hn);
                        setTabAt(tab, i, fwd);
                        advance = true;
                    }
                }
            }
        }
    }
}
```

首先看任务分配逻辑，前面通过stride计算把桶分成了好几份，每次领取任务获取stride份，获取的区间是[bound,i]，值得说明的是：

每次只能由一个线程获取任务，cas加锁加的是TRANSFERINDEX，一个线程没获取完任务，其他线程领不了

```java
    while (advance) {
        int nextIndex, nextBound;
        if (--i >= bound || finishing)
            advance = false;
        else if ((nextIndex = transferIndex) <= 0) {
            i = -1;
            advance = false;
        }
        else if (U.compareAndSetInt
                 (this, TRANSFERINDEX, nextIndex,
                  nextBound = (nextIndex > stride ?
                               nextIndex - stride : 0))) {
            // 计算出区间边界值
            bound = nextBound;
            i = nextIndex - 1;
            advance = false;
        }
    }
```



接着我们看看迁移完成检查

```java
// i为任务后界。i>-n代表原表已经遍历完了，i + n >= nextn做了个保险工作
if (i < 0 || i >= n || i + n >= nextn) {
    int sc;
    // finishing为true代表完成了
    if (finishing) {
        nextTable = null;  //清空临时扩容变
        table = nextTab;  // 最后才会覆盖。所以这时候get获取元素没有影响的，这个是保护性覆盖
        sizeCtl = (n << 1) - (n >>> 1);   // 这里相当于2n-0.25n,也就是1.75n。下次扩容阈值为1.75n
        return;
    }
    // 这里的sizeCtl是个负数，高16位记录的是扩容标识，低16位记录的是协助线程数
    if (U.compareAndSetInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {
        // 如果不是最后退出的线程，就直接退出
        if ((sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT)
            return;
        // 最后退出的线程要做收尾工作
        finishing = advance = true;
        i = n; // recheck before commit
    }
}
```

sizeCtl我们需要解释一下。在扩容的时候，这个值就不代表初始容量或者是扩容阈值了，他前16位代表扩容标识，后16位代表协助线程数,他是在面addCount做更改的。

![image-20250409114743591](C:\Users\59755\AppData\Roaming\Typora\typora-user-images\image-20250409114743591.png)



其他状态位处理

```java
    // 空桶处理，插入一个fordwardNode节点，i是区间尾部，这里相当于获取尾部的桶
    else if ((f = tabAt(tab, i)) == null)
        advance = casTabAt(tab, i, null, fwd);
    // 已处理桶,桶的头是MOVED，也就是以及处理了，不用再处理了
    else if ((fh = f.hash) == MOVED)
        // 标记advance为true
        advance = true; // already processed
```

看看这段，fh是最后的节点的hash

```java
else {
    // 给链表的头节点加synchronized，防止出现类似jdk7使用头插法后出现的死链问题
    synchronized (f) {
        if (tabAt(tab, i) == f) {
            Node<K,V> ln, hn;
            if (fh >= 0) {
                // 单独计算头节点，不然后面 if (b != runBit)没法判断
                // 这里的n是旧表长度
                int runBit = fh & n;
                Node<K,V> lastRun = f;
                // 从区间的最后一个节点开始，遍历链表
                for (Node<K,V> p = f.next; p != null; p = p.next) {
                    int b = p.hash & n;
                    if (b != runBit) {
                        runBit = b;
                        lastRun = p;
                    }
                }
                // 重用最后一段节点？
                if (runBit == 0) {
                    ln = lastRun;
                    hn = null;
                }
                else {
                    hn = lastRun;
                    ln = null;
                }
                
                for (Node<K,V> p = f; p != lastRun; p = p.next) {
                    int ph = p.hash; K pk = p.key; V pv = p.val;
                    if ((ph & n) == 0)
                        ln = new Node<K,V>(ph, pk, pv, ln);
                    else
                        hn = new Node<K,V>(ph, pk, pv, hn);
                }
                setTabAt(nextTab, i, ln);
                setTabAt(nextTab, i + n, hn);
                setTabAt(tab, i, fwd);
                advance = true;
            }
            else if (f instanceof TreeBin) {
                TreeBin<K,V> t = (TreeBin<K,V>)f;
                TreeNode<K,V> lo = null, loTail = null;
                TreeNode<K,V> hi = null, hiTail = null;
                int lc = 0, hc = 0;
                for (Node<K,V> e = t.first; e != null; e = e.next) {
                    int h = e.hash;
                    TreeNode<K,V> p = new TreeNode<K,V>
                        (h, e.key, e.val, null, null);
                    if ((h & n) == 0) {
                        if ((p.prev = loTail) == null)
                            lo = p;
                        else
                            loTail.next = p;
                        loTail = p;
                        ++lc;
                    }
                    else {
                        if ((p.prev = hiTail) == null)
                            hi = p;
                        else
                            hiTail.next = p;
                        hiTail = p;
                        ++hc;
                    }
                }
                ln = (lc <= UNTREEIFY_THRESHOLD) ? untreeify(lo) :
                    (hc != 0) ? new TreeBin<K,V>(lo) : t;
                hn = (hc <= UNTREEIFY_THRESHOLD) ? untreeify(hi) :
                    (lc != 0) ? new TreeBin<K,V>(hi) : t;
                setTabAt(nextTab, i, ln);
                setTabAt(nextTab, i + n, hn);
                setTabAt(tab, i, fwd);
                advance = true;
            }
        }
    }
}
```



从领取任务的区间的最后一个节点的头节点开始遍历，遍历链表，这里的目的是用来找出。尾部那一段，在新链表中hash值相同（也就是会被防止同一个桶）的连续性链表，用于整段迁移。

比如计算出新链表的hash值  A（0）-》b(16)->c(16)->d(0)->e(0)，那么这段的结果就会记录最后一段连续性的链表d->e,runBit和lastRun记录的都是d的数据

这里还有一个问题：为什么要与旧表长度做与运算，不用新表长度呢，我们知道扩容都是2的n次方，假如原表的长度是16，新表的长度就是32

   10000     -----------16

假如 hash & 16 =0，意味着hash小于16.那么就可以保留在原来的位置，hash & 16>0意味着需要迁移，也就是以16为分界线判断是否需要迁移

```java
                // 单独计算头节点，不然后面 if (b != runBit)没法判断
// 这里的n是旧表长度，
                int runBit = fh & n;
                Node<K,V> lastRun = f;
                // 从区间的最后一个节点开始，遍历链表
                // 这里的n是旧表长度
                for (Node<K,V> p = f.next; p != null; p = p.next) {
                    int b = p.hash & n;
                    if (b != runBit) {
                        runBit = b;
                        lastRun = p;
                    }
                }
```

接着就是实际的迁移机制了

迁移的机制需要解释一下

前面我们知道了迁移分为两部分：扩容后仍在原桶位置（ ph & n ==0）和扩容后在新桶位置的。前面if (runBit == 0){...}else{.....}就是用来记录这个的

循环内：整体迁移的部分一样放在尾部。除去这部分倒序。下面举个例子

原链表为:A(0)->B(0)->C(0)->D(1)->E(1)，其中括号中的数字为&n的结果，这里D->E是需要做整体迁移的，lastRun是D的位置，runBit 是D位置的hash值。&n结果为1，他会走else，也就是 hn = lastRun；进入循环后，第一个节点与运算结果为0，走if ((ph & n) == 0)，循环第二次循环到B，同样走if ((ph & n) == 0)，那就变成了B->A,同样，最后会变成C->B->A（这种也叫头插法），最后

setTabAt(nextTab, i, ln);设置了C-B-A

而 setTabAt(nextTab, i + n, hn);设置了D->E

```java
            // ln是lowNode的意思，也就是低区间链表，就是迁移后仍在原桶位置的链表
           // hn是扩容后迁移到新桶的链表
			if (runBit == 0) {
                ln = lastRun;
                hn = null;
            }
            else {
                hn = lastRun;
                ln = null;
            }
            // 遍历这个链表，p是链表头部，lastRun的链表做整体迁移
      
            for (Node<K,V> p = f; p != lastRun; p = p.next) {
                int ph = p.hash; K pk = p.key; V pv = p.val;
                if ((ph & n) == 0)
                    ln = new Node<K,V>(ph, pk, pv, ln);
                else
                    hn = new Node<K,V>(ph, pk, pv, hn);
            }
            setTabAt(nextTab, i, ln);
            setTabAt(nextTab, i + n, hn);
           // 迁移完成的链表在原桶中放置一个fwd节点，标志迁移完成
            setTabAt(tab, i, fwd);
            advance = true;
```

---

#### jdk7中的CurrentHashMap

jdk7的桶实际上是一个基础aqs的类，名为segement。操作时用segement进行加锁

---

####  遗留问题：

由于不懂红黑树，所以红黑树相关的都掠过了
